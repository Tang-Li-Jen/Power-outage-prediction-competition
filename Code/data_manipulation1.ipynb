{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import training and testing dataset\n",
    "data_path = 'D:\\\\Users\\\\Qoo\\\\Desktop\\\\taipower\\\\data\\\\'\n",
    "train = pd.read_csv(data_path + 'train.csv')\n",
    "test = pd.read_csv(data_path+ 'submit.csv')\n",
    "\n",
    "# merge training and testing data\n",
    "df = pd.merge(train,test,how='inner',\n",
    "        on=['CityName','TownName','VilName','VilCode'])\n",
    "\n",
    "# transpose columns to rows\n",
    "var_names = list(df.columns)\n",
    "df2 = pd.melt(df,id_vars=['CityName','TownName','VilName','VilCode'],value_vars=var_names[4:len(var_names)],\n",
    "              var_name='typhoon',value_name='elect_down')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of typhoon alert : 19\n",
      "set(['NESATANDHAITANG', 'MERANTIANDMALAKAS'])\n"
     ]
    }
   ],
   "source": [
    "# typhoon alert dataset \n",
    "# data source: http://rdc28.cwb.gov.tw/TDB/ntdb/pageControl/ty_warning\n",
    "typhoon = pd.read_csv(data_path + 'typhoon_alert.csv',encoding='big5')\n",
    "\n",
    "# extract typhoon alert period \n",
    "i = iter(list(typhoon.duration))\n",
    "duration = zip(i,i)\n",
    "typhoon_time = pd.DataFrame(duration, columns=['arrive','leave'])\n",
    "cols = list(typhoon)\n",
    "cols.remove('duration')\n",
    "tp = typhoon.loc[0:len(typhoon):2,cols]\n",
    "tp = tp.reset_index(drop=True)\n",
    "tp2 = pd.concat([tp,typhoon_time],axis=1,join_axes=[tp.index])\n",
    "tp2.arrive = pd.to_datetime(tp2.arrive)\n",
    "tp2.leave = pd.to_datetime(tp2.leave)\n",
    "tp2.year = tp2.arrive.dt.year\n",
    "\n",
    "# extract typhoon alert between training set time period\n",
    "mask = (tp2.year >=2014) & (tp2.year<=2017)\n",
    "tp3 = tp2[mask]\n",
    "\n",
    "print 'total number of typhoon alert : %s' %len(tp3)\n",
    "# ckeck missing typhoon alert data in df2 \n",
    "print set(df2.typhoon.str.upper()) - set(tp3.en_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# create values for two special typhoons\n",
    "# MERANTIANDMALAKAS\n",
    "MERANTIANDMALAKAS = tp3.loc[(tp3.en_name =='MALAKAS') | (tp3.en_name =='MERANTI'),]\n",
    "#print MERANTIANDMALAKAS\n",
    "tp3.loc[19,6:11] = MERANTIANDMALAKAS.iloc[:,6:11].astype(np.int16).max()\n",
    "tp3.iloc[19,[0,1,2,3,4,5,11,12]] = [2016,201615,u'莫蘭蒂及馬勒卡',u'MERANTIANDMALAKAS','7',u'強烈',pd.to_datetime('2016-09-12 23:30:00'),pd.to_datetime('2016-09-18 08:30')]\n",
    "\n",
    "# NESATANDHAITANG\n",
    "NESATANDHAITANG = tp3.loc[(tp3.en_name =='NESAT') | (tp3.en_name =='HAITANG'),]\n",
    "#print NESATANDHAITANG\n",
    "tp3.loc[20,6:11] = NESATANDHAITANG.iloc[:,[6,7,8,10]].astype(np.int16).max()\n",
    "tp3.iloc[20,[0,1,2,3,4,5,9,11,12]] = [2017,201711,u'尼莎及海棠',u'NESATANDHAITANG','---',u'中度',60,pd.to_datetime('2017-07-28 08:30'),pd.to_datetime('2017-07-31 08:30')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.typhoon = df2.typhoon.str.upper()\n",
    "df3 = pd.merge(df2, tp3, how='left',left_on='typhoon', right_on='en_name' )\n",
    "print len(df3)\n",
    "\n",
    "#ckeck we have all typhoon alert data\n",
    "set(df2.typhoon.str.upper()) - set(tp3.en_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process on typhoon alert variables\n",
    "# r10_km\n",
    "df3.loc[df3.r10_km =='---','r10_km'] = '0'\n",
    "\n",
    "#typhoon type\n",
    "df3.loc[df3.type ==u'---','type'] = 0\n",
    "df3.loc[df3.type ==u'特殊','type'] = 10\n",
    "\n",
    "#typhoon magnitude\n",
    "df3.loc[df3.magnitude ==u'輕度','magnitude'] = 1\n",
    "df3.loc[df3.magnitude ==u'中度','magnitude'] = 2\n",
    "df3.loc[df3.magnitude ==u'強烈','magnitude'] = 3\n",
    "\n",
    "# time-related variables on arrive_datetime \n",
    "df3.loc[:,'arrive_month'] = df3.arrive.dt.month\n",
    "df3.loc[:,'arrive_hour'] = df3.arrive.dt.hour\n",
    "df3.loc[:,'arrive_weekday'] = df3.arrive.dt.weekday\n",
    "df3.loc[:,'arrive_week'] = df3.arrive.dt.week\n",
    "df3.loc[:,'duration'] = df3.leave - df3.arrive\n",
    "df3.loc[:,'duration_h'] = df3.duration.dt.total_seconds() / 3600\n",
    "\n",
    "df3.year = df3.year.astype('float')\n",
    "df3.hpa = df3.hpa.astype('float')\n",
    "df3.wind_speed = df3.wind_speed.astype('float')\n",
    "df3.r7_km = df3.r7_km.astype('float')\n",
    "df3.r10_km = df3.r10_km.astype('float')\n",
    "df3.alert_level = df3.alert_level.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check electric pole files' encoding\n",
    "all_files = glob.glob(os.path.join(data_path+'poledata/','*.csv'))\n",
    "for file in all_files:\n",
    "    try:\n",
    "        pd.read_csv(file,encoding='utf-8',usecols=[0,1,2,3])\n",
    "    except:\n",
    "        print 'error at %s' %file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total files number : 24\n"
     ]
    }
   ],
   "source": [
    "# import multiple electric pole dataset\n",
    "print 'total files number : %s' %len(glob.glob(os.path.join(data_path+'poledata/','*.csv')))\n",
    "pole = pd.concat(pd.read_csv(file,encoding='utf-8',usecols=[0,1,2,3,4]) for file in all_files )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename dataframe\n",
    "old_names = list(pole.columns)\n",
    "new_names = ['CityName','TownName','VilName','coordinate','p_type']\n",
    "pole.rename(columns=dict(zip(old_names,new_names)),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are god-damn right!\n"
     ]
    }
   ],
   "source": [
    "#check total sample size is correct\n",
    "L =[]\n",
    "for file in all_files:\n",
    "    L.append(len(pd.read_csv(file,encoding='utf-8',usecols=[0])))\n",
    "if len(pole) == sum(L):\n",
    "    print 'you are god-damn right!'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique VilCode:7677\n",
      "after sample amount:2864118\n"
     ]
    }
   ],
   "source": [
    "print 'number of unique VilCode:{}'.format(len(pole.groupby(['CityName','TownName','VilName'],as_index=False).count()))\n",
    "print 'after sample amount:{}'.format(len(pole))\n",
    "#pole.groupby(['CityName','TownName','VilName'],as_index=False).count()[['CityName','TownName','VilName']].to_csv('D:/Users/Qoo/Desktop/pole_before.csv',index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean wrong words\n",
    "pole.CityName = pole.CityName.replace({u'臺':u'台'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'臺':u'台'},regex=True)\n",
    "pole.TownName = pole.TownName.replace({u'頭份鎮':u'頭份市'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'磚瑤里':u'磚磘里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'部下村':u'廍下村'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'回瑤里':u'硘磘里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'石弄村':u'石硦村'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'鹽館村':u'塩館村'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'瑞峰村':u'瑞峯村'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'部子里':u'廍子里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'龜殼里':u'龜壳村'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'蔗部里':u'蔗廍里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'慷榔里':u'槺榔里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'雙龍里':u'双龍里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'糖部里':u'糖廍里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'康榔里':u'槺榔里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'那拔里':u'𦰡拔里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'鹽洲里':u'塩洲里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'鹽行里':u'塩行里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'石曹里':u'石𥕢里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'土板村':u'土坂村'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'台板村':u'台坂村'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'里龍里':u'里壠里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'雙福村':u'双福村'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'文峰村':u'文峯村'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'響林村':u'响林村'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'廈北村':u'厦北村'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'廈南村':u'厦南村'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'涼山村':u'凉山村'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'崎峰村':u'崎峯村'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'大峰里':u'大峯里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'南館村':u'南舘村'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'埤腳村':u'埤脚村'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'新館村':u'新舘村'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'舊館村':u'舊舘村'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'南磘里':u'南瑤里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'永館里':u'永舘里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'上館里':u'上舘里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'峰廷里':u'峯廷里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'五峰里':u'五峯里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'爪峰里':u'爪峯里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'崙峰里':u'崙峯里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'峰山里':u'峯山里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'槍寮里':u'獇寮里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'濂新里':u'濓新里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'濂洞里':u'濓洞里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'崁腳里':u'崁脚里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'水砌村':u'水磜村'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'雞林里':u'鷄林里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'果林里':u'菓林里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'果葉村':u'菓葉村'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'時裡里':u'嵵裡里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'雙潭村':u'双潭村'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'雙湖村':u'双湖村'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'板里村':u'坂里村'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'柏子村':u'萡子村'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'柏東村':u'萡東村'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'帝埔里':u'坔埔里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'瓦瑤村':u'瓦磘村'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'瓦瑤里':u'瓦磘里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'灰瑤里':u'灰磘里'},regex=True)\n",
    "pole.VilName = pole.VilName.replace({u'部':u'廍'},regex=True)\n",
    "#\n",
    "pole.loc[(pole.CityName.str.contains(u'台中市'))&(pole.TownName.str.contains(u'西區'))\n",
    "    ,'VilName'] = pole.loc[(pole.CityName.str.contains(u'台中市'))&(pole.TownName.str.contains(u'西區'))\n",
    "    ,'VilName'].replace({u'公館里':u'公舘里'},regex=True)\n",
    "pole.loc[(pole.CityName.str.contains(u'台南市'))&(pole.TownName.str.contains(u'七股區'))\n",
    "    ,'VilName'] = pole.loc[(pole.CityName.str.contains(u'台南市'))&(pole.TownName.str.contains(u'七股區'))\n",
    "    ,'VilName'].replace({u'鹽埕里':u'塩埕里'},regex=True)\n",
    "pole.loc[(pole.CityName.str.contains(u'台南市'))&(pole.TownName.str.contains(u'安南區'))\n",
    "    ,'VilName'] = pole.loc[(pole.CityName.str.contains(u'台南市'))&(pole.TownName.str.contains(u'安南區'))\n",
    "    ,'VilName'].replace({u'鹽田里':u'塩田里'},regex=True)\n",
    "pole.loc[(pole.CityName.str.contains(u'台南市'))&(pole.TownName.str.contains(u'山上區'))\n",
    "    ,'VilName'] = pole.loc[(pole.CityName.str.contains(u'台南市'))&(pole.TownName.str.contains(u'山上區'))\n",
    "    ,'VilName'].replace({u'玉峰里':u'玉峯里'},regex=True)\n",
    "pole.loc[(pole.CityName.str.contains(u'台南市'))&(pole.TownName.str.contains(u'新化區'))\n",
    "    ,'VilName'] = pole.loc[(pole.CityName.str.contains(u'台南市'))&(pole.TownName.str.contains(u'新化區'))\n",
    "    ,'VilName'].replace({u'山腳里':u'山脚里'},regex=True)\n",
    "pole.loc[(pole.CityName.str.contains(u'台東縣'))&(pole.TownName.str.contains(u'綠島鄉'))\n",
    "    ,'VilName'] = pole.loc[(pole.CityName.str.contains(u'台東縣'))&(pole.TownName.str.contains(u'綠島鄉'))\n",
    "    ,'VilName'].replace({u'公館村':u'公舘村'},regex=True)\n",
    "pole.loc[(pole.CityName.str.contains(u'嘉義縣'))&(pole.TownName.str.contains(u'朴子市'))\n",
    "    ,'VilName'] = pole.loc[(pole.CityName.str.contains(u'嘉義縣'))&(pole.TownName.str.contains(u'朴子市'))\n",
    "    ,'VilName'].replace({u'雙溪里':u'双溪里'},regex=True)\n",
    "pole.loc[(pole.CityName.str.contains(u'嘉義縣'))&(pole.TownName.str.contains(u'梅山鄉'))\n",
    "    ,'VilName'] = pole.loc[(pole.CityName.str.contains(u'嘉義縣'))&(pole.TownName.str.contains(u'梅山鄉'))\n",
    "    ,'VilName'].replace({u'雙溪村':u'双溪村'},regex=True)\n",
    "pole.loc[(pole.CityName.str.contains(u'新北市'))&(pole.TownName.str.contains(u'板橋區'))\n",
    "    ,'VilName'] = pole.loc[(pole.CityName.str.contains(u'新北市'))&(pole.TownName.str.contains(u'板橋區'))\n",
    "    ,'VilName'].replace({u'公館里':u'公舘里'},regex=True)\n",
    "pole.loc[(pole.CityName.str.contains(u'苗栗縣'))&(pole.TownName.str.contains(u'竹南鎮'))\n",
    "    ,'VilName'] = pole.loc[(pole.CityName.str.contains(u'苗栗縣'))&(pole.TownName.str.contains(u'竹南鎮'))\n",
    "    ,'VilName'].replace({u'公館里':u'公舘里'},regex=True)\n",
    "pole.loc[(pole.CityName.str.contains(u'雲林縣'))&(pole.TownName.str.contains(u'北港鎮'))\n",
    "    ,'VilName'] = pole.loc[(pole.CityName.str.contains(u'雲林縣'))&(pole.TownName.str.contains(u'北港鎮'))\n",
    "    ,'VilName'].replace({u'公館里':u'公舘里'},regex=True)\n",
    "pole.loc[(pole.CityName.str.contains(u'雲林縣'))&(pole.TownName.str.contains(u'西螺鎮'))\n",
    "    ,'VilName'] = pole.loc[(pole.CityName.str.contains(u'雲林縣'))&(pole.TownName.str.contains(u'西螺鎮'))\n",
    "    ,'VilName'].replace({u'公館里':u'公舘里'},regex=True)\n",
    "pole.loc[(pole.CityName.str.contains(u'高雄市'))&(pole.TownName.str.contains(u'湖內區'))\n",
    "    ,'VilName'] = pole.loc[(pole.CityName.str.contains(u'高雄市'))&(pole.TownName.str.contains(u'湖內區'))\n",
    "    ,'VilName'].replace({u'公館里':u'公舘里'},regex=True)\n",
    "pole.loc[(pole.CityName.str.contains(u'苗栗縣'))&(pole.TownName.str.contains(u'苑裡鎮'))\n",
    "    ,'VilName'] = pole.loc[(pole.CityName.str.contains(u'苗栗縣'))&(pole.TownName.str.contains(u'苑裡鎮'))\n",
    "    ,'VilName'].replace({u'山腳里':u'山脚里'},regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique VilCode:7675\n",
      "after sample amount:2864118\n"
     ]
    }
   ],
   "source": [
    "print 'number of unique VilCode:{}'.format(len(pole.groupby(['CityName','TownName','VilName'],as_index=False).count()))\n",
    "print 'after sample amount:{}'.format(len(pole))\n",
    "#pole.groupby(['CityName','TownName','VilName'],as_index=False).count()[['CityName','TownName','VilName']].to_csv('D:/Users/Qoo/Desktop/pole_after.csv',index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of pole type in village\n",
    "p1 = pole.groupby(['CityName','TownName','VilName'],as_index=False).agg({'p_type':'nunique'})\n",
    "p1.columns.values[3] = 'pole_type_counts'\n",
    "\n",
    "# the number of each type's pole in village\n",
    "p2 = pole.groupby(['CityName','TownName','VilName','p_type'],as_index=False).count()\n",
    "p2 = p2.pivot_table(index=['CityName','TownName','VilName'],columns='p_type',values='coordinate')\n",
    "p2 = p2.reset_index()\n",
    "p2 = p2.fillna(0)\n",
    "p2.columns.values[3:13] =['p%s' % s for s in range(1,11)] \n",
    "\n",
    "# total number of pole in village\n",
    "p3 = pole.groupby(['CityName','TownName','VilName'],as_index=False).count()\n",
    "p3.columns.values[3] = 'pole_counts'\n",
    "p3 = p3.iloc[:,[0,1,2,3]]\n",
    "\n",
    "#transform columns value from unicode to str\n",
    "for data in [p1,p2,p3]:\n",
    "    for column in ['CityName','TownName','VilName']:\n",
    "        data[column] =  data[column].str.encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.CityName = df3.CityName.replace({'臺':'台'},regex=True)\n",
    "df3.VilName = df3.VilName.replace({'臺':'台'},regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3.CityName = df3.CityName.replace({'臺':'台'},regex=True)\n",
    "df3 = pd.merge(df3,p1,how='left',on=['CityName','TownName','VilName'])\n",
    "df3 = pd.merge(df3,p2,how='left',on=['CityName','TownName','VilName'])\n",
    "df3 = pd.merge(df3,p3,how='left',on=['CityName','TownName','VilName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute missing value\n",
    "df3 = df3.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two typhoons or not\n",
    "df3['double_kill'] = 0\n",
    "df3.loc[(df3.typhoon =='NESATANDHAITANG')|(df3.typhoon =='MERANTIANDMALAKAS'),'double_kill'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# population density in Taiwan \n",
    "# data source: https://data.gov.tw/dataset/8410\n",
    "pop_files = glob.glob(os.path.join(data_path+'population/','*.csv'))\n",
    "population = pd.concat(pd.read_csv(d, skiprows=2, nrows=370, names=['Minguo_year','location',\n",
    "            'people_total','area','population_density'] ) for d in pop_files)\n",
    "population['CityName'] = population.location.str.slice(0,9)\n",
    "population['TownName'] = population.location.str.slice(9,)\n",
    "\n",
    "# clean word\n",
    "population.CityName = population.CityName.replace({'臺':'台'},regex=True)\n",
    "population.TownName = population.TownName.replace({'員林鎮':'員林市'},regex=True)\n",
    "population.TownName = population.TownName.replace({'頭份鎮':'頭份市'},regex=True)\n",
    "\n",
    "# merge data\n",
    "df3.loc[df3.year == 2017,'Minguo_year'] =105\n",
    "df3.loc[df3.year == 2016,'Minguo_year'] =105\n",
    "df3.loc[df3.year == 2015,'Minguo_year'] =104\n",
    "df3.loc[df3.year == 2014,'Minguo_year'] =103\n",
    "df3.loc[df3.year == 2013,'Minguo_year'] =102\n",
    "df3 = pd.merge(df3, population, how='left',on=['CityName','TownName','Minguo_year'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv('D:/Users/Qoo/Desktop/df.csv',index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
